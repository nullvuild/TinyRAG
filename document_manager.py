import os
import chromadb
from sentence_transformers import SentenceTransformer
import hashlib
import warnings
from config import load_settings, get_docs_path

# ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", message=".*encoder_attention_mask.*")
warnings.filterwarnings("ignore", message=".*torch.*")

# ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤
try:
    from docx import Document  # Word íŒŒì¼
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False

try:
    import PyPDF2  # PDF íŒŒì¼
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False

try:
    import openpyxl  # Excel íŒŒì¼
    EXCEL_AVAILABLE = True
except ImportError:
    EXCEL_AVAILABLE = False

try:
    from pptx import Presentation  # PowerPoint íŒŒì¼
    PPTX_AVAILABLE = True
except ImportError:
    PPTX_AVAILABLE = False

try:
    import fitz  # PyMuPDF (ë” ë‚˜ì€ PDF ì²˜ë¦¬)
    PYMUPDF_AVAILABLE = True
except ImportError:
    PYMUPDF_AVAILABLE = False

try:
    from markitdown import MarkItDown  # Microsoftì˜ í†µí•© ë¬¸ì„œ ë³€í™˜ ë¼ì´ë¸ŒëŸ¬ë¦¬
    MARKITDOWN_AVAILABLE = True
except ImportError:
    MARKITDOWN_AVAILABLE = False

print("=== TinyRAG - ê°€ë²¼ìš´ ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ ===")

class DocumentProcessor:
    def __init__(self, settings_file="settings.json"):
        # ì„¤ì • ë¡œë“œ
        self.settings = load_settings(settings_file)
        
        self.db_path = self.settings["paths"]["chroma_db"]
        self.model_path = self.settings["embedding_model"]["local_path"]
        
        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        print("ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘...")
        self.client = chromadb.PersistentClient(path=self.db_path)
        
        # SentenceTransformer ëª¨ë¸ ë¡œë”©
        print("ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.model = SentenceTransformer(self.model_path)
        
        # MarkItDown ì´ˆê¸°í™” (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
        if MARKITDOWN_AVAILABLE:
            print("MarkItDown ë¬¸ì„œ ë³€í™˜ê¸° ì´ˆê¸°í™” ì¤‘...")
            self.markitdown = MarkItDown()
        else:
            self.markitdown = None
            
        print("âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def split_text(self, text, chunk_size=None, overlap=None):
        """í…ìŠ¤íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ êµ¬ë¶„ì ì—ì„œ ì²­í¬ë¡œ ë¶„í• """
        if chunk_size is None:
            chunk_size = self.settings["search"]["chunk_size"]
        if overlap is None:
            overlap = self.settings["search"]["overlap"]
            
        chunks = []
        metadata = []
        start = 0
        chunk_id = 0
        
        while start < len(text):
            end = start + chunk_size
            
            # í…ìŠ¤íŠ¸ ëì— ë„ë‹¬í•œ ê²½ìš°
            if end >= len(text):
                chunk_text = text[start:].strip()
            else:
                # ìì—°ìŠ¤ëŸ¬ìš´ êµ¬ë¶„ì ì—ì„œ ìë¥´ê¸°
                potential_chunk = text[start:end]
                
                # 1. ë¬¸ì¥ì˜ ë(.)ì—ì„œ ìë¥´ê¸° ì‹œë„
                last_period = potential_chunk.rfind('.')
                if last_period > chunk_size * 0.7:  # ë„ˆë¬´ ì§§ì§€ ì•Šë‹¤ë©´
                    actual_end = start + last_period + 1
                    chunk_text = text[start:actual_end].strip()
                else:
                    # 2. ì¤„ë°”ê¿ˆì—ì„œ ìë¥´ê¸° ì‹œë„
                    last_newline = potential_chunk.rfind('\n')
                    if last_newline > chunk_size * 0.7:
                        actual_end = start + last_newline
                        chunk_text = text[start:actual_end].strip()
                    else:
                        # 3. ê³µë°±ì—ì„œ ìë¥´ê¸° ì‹œë„
                        last_space = potential_chunk.rfind(' ')
                        if last_space > chunk_size * 0.7:
                            actual_end = start + last_space
                            chunk_text = text[start:actual_end].strip()
                        else:
                            # 4. ë§ˆì§€ë§‰ ìˆ˜ë‹¨ìœ¼ë¡œ ì›ë˜ í¬ê¸°ì—ì„œ ìë¥´ê¸°
                            chunk_text = potential_chunk.strip()
                            actual_end = end
            
            if chunk_text:  # ë¹ˆ ì²­í¬ ì œì™¸
                chunks.append(chunk_text)
                metadata.append({
                    "chunk_id": chunk_id,
                    "start_pos": start,
                    "end_pos": min(actual_end if 'actual_end' in locals() else end, len(text)),
                    "length": len(chunk_text)
                })
                chunk_id += 1
            
            # ë‹¤ìŒ ì²­í¬ ì‹œì‘ì  ê³„ì‚° (ê²¹ì¹¨ ê³ ë ¤)
            if 'actual_end' in locals():
                start = max(actual_end - overlap, start + 1)
                del actual_end  # ë³€ìˆ˜ ì´ˆê¸°í™”
            else:
                start += chunk_size - overlap
        
        return chunks, metadata
    
    def get_supported_extensions(self):
        """ì§€ì›ë˜ëŠ” íŒŒì¼ í™•ì¥ì ëª©ë¡ ë°˜í™˜"""
        extensions = ['.txt', '.md']  # ê¸°ë³¸ í…ìŠ¤íŠ¸ íŒŒì¼
        
        if DOCX_AVAILABLE:
            extensions.extend(['.docx', '.doc'])
        if PDF_AVAILABLE or PYMUPDF_AVAILABLE:
            extensions.append('.pdf')
        if EXCEL_AVAILABLE:
            extensions.extend(['.xlsx', '.xls'])
        if PPTX_AVAILABLE:
            extensions.extend(['.pptx', '.ppt'])
            
        return extensions
    
    def read_word_file(self, file_path):
        """Word íŒŒì¼ì„ Markdown í˜•ì‹ìœ¼ë¡œ ì½ê¸° - MarkItDown ìš°ì„  ì‚¬ìš©"""
        # MarkItDown ìš°ì„  ì‹œë„
        if MARKITDOWN_AVAILABLE:
            content = self.read_office_file_with_markitdown(file_path)
            if content is not None:
                return content
        
        # MarkItDown ì‹¤íŒ¨ì‹œ ê¸°ì¡´ ë°©ë²• ì‚¬ìš©
        if not DOCX_AVAILABLE:
            raise ValueError("python-docx ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            doc = Document(file_path)
            markdown_content = []
            
            for paragraph in doc.paragraphs:
                text = paragraph.text.strip()
                if not text:
                    continue
                    
                # ì œëª© ìŠ¤íƒ€ì¼ ì²˜ë¦¬
                if paragraph.style.name.startswith('Heading'):
                    level = paragraph.style.name.replace('Heading ', '')
                    if level.isdigit():
                        markdown_content.append(f"{'#' * int(level)} {text}")
                    else:
                        markdown_content.append(f"## {text}")
                else:
                    markdown_content.append(text)
            
            # í‘œ ì²˜ë¦¬
            for table in doc.tables:
                markdown_content.append("\n| " + " | ".join([cell.text for cell in table.rows[0].cells]) + " |")
                markdown_content.append("| " + " | ".join(["---"] * len(table.rows[0].cells)) + " |")
                for row in table.rows[1:]:
                    markdown_content.append("| " + " | ".join([cell.text for cell in row.cells]) + " |")
                markdown_content.append("")
            
            return "\n\n".join(markdown_content)
        except Exception as e:
            raise ValueError(f"Word íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
    
    def read_pdf_file(self, file_path):
        """PDF íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ì½ê¸° - MarkItDown ìš°ì„  ì‚¬ìš©"""
        if MARKITDOWN_AVAILABLE:
            return self._read_pdf_markitdown(file_path)
        elif PYMUPDF_AVAILABLE:
            return self._read_pdf_pymupdf(file_path)
        elif PDF_AVAILABLE:
            return self._read_pdf_pypdf2(file_path)
        else:
            raise ValueError("PDF ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    def _read_pdf_markitdown(self, file_path):
        """MarkItDownì„ ì‚¬ìš©í•œ PDF ì½ê¸° (ìµœê³  í’ˆì§ˆ)"""
        try:
            print("MarkItDownì„ ì‚¬ìš©í•˜ì—¬ PDF ë³€í™˜ ì¤‘...")
            result = self.markitdown.convert(file_path)
            return result.text_content
        except Exception as e:
            print(f"âš ï¸ MarkItDown ë³€í™˜ ì‹¤íŒ¨, PyMuPDFë¡œ ëŒ€ì²´ ì‹œë„: {e}")
            # MarkItDown ì‹¤íŒ¨ì‹œ ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ëŒ€ì²´
            if PYMUPDF_AVAILABLE:
                return self._read_pdf_pymupdf(file_path)
            elif PDF_AVAILABLE:
                return self._read_pdf_pypdf2(file_path)
            else:
                raise ValueError(f"PDF íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ (MarkItDown): {e}")
    
    def _read_pdf_pymupdf(self, file_path):
        """PyMuPDFë¥¼ ì‚¬ìš©í•œ PDF ì½ê¸° (ë” ì •í™•í•¨)"""
        try:
            doc = fitz.open(file_path)
            text_content = []
            
            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                text = page.get_text()
                if text.strip():
                    text_content.append(f"## í˜ì´ì§€ {page_num + 1}\n\n{text}")
            
            doc.close()
            return "\n\n".join(text_content)
        except Exception as e:
            raise ValueError(f"PDF íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ (PyMuPDF): {e}")
    
    def _read_pdf_pypdf2(self, file_path):
        """PyPDF2ë¥¼ ì‚¬ìš©í•œ PDF ì½ê¸°"""
        try:
            with open(file_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                text_content = []
                
                for page_num, page in enumerate(pdf_reader.pages):
                    text = page.extract_text()
                    if text.strip():
                        text_content.append(f"## í˜ì´ì§€ {page_num + 1}\n\n{text}")
                
                return "\n\n".join(text_content)
        except Exception as e:
            raise ValueError(f"PDF íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ (PyPDF2): {e}")
    
    def read_excel_file(self, file_path):
        """Excel íŒŒì¼ì„ Markdown í‘œ í˜•ì‹ìœ¼ë¡œ ì½ê¸° - MarkItDown ìš°ì„  ì‚¬ìš©"""
        # MarkItDown ìš°ì„  ì‹œë„
        if MARKITDOWN_AVAILABLE:
            content = self.read_office_file_with_markitdown(file_path)
            if content is not None:
                return content
        
        # MarkItDown ì‹¤íŒ¨ì‹œ ê¸°ì¡´ ë°©ë²• ì‚¬ìš©
        if not EXCEL_AVAILABLE:
            raise ValueError("openpyxl ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            workbook = openpyxl.load_workbook(file_path, data_only=True)
            markdown_content = []
            
            for sheet_name in workbook.sheetnames:
                sheet = workbook[sheet_name]
                markdown_content.append(f"# ì‹œíŠ¸: {sheet_name}\n")
                
                # ë°ì´í„°ê°€ ìˆëŠ” ì˜ì—­ ì°¾ê¸°
                max_row = sheet.max_row
                max_col = sheet.max_column
                
                if max_row > 0 and max_col > 0:
                    # í—¤ë” í–‰
                    header_row = []
                    for col in range(1, max_col + 1):
                        cell_value = sheet.cell(row=1, column=col).value
                        header_row.append(str(cell_value) if cell_value is not None else "")
                    
                    markdown_content.append("| " + " | ".join(header_row) + " |")
                    markdown_content.append("| " + " | ".join(["---"] * len(header_row)) + " |")
                    
                    # ë°ì´í„° í–‰ë“¤
                    for row in range(2, min(max_row + 1, 101)):  # ìµœëŒ€ 100í–‰ê¹Œì§€ë§Œ
                        data_row = []
                        for col in range(1, max_col + 1):
                            cell_value = sheet.cell(row=row, column=col).value
                            data_row.append(str(cell_value) if cell_value is not None else "")
                        markdown_content.append("| " + " | ".join(data_row) + " |")
                
                markdown_content.append("")
            
            return "\n\n".join(markdown_content)
        except Exception as e:
            raise ValueError(f"Excel íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
    
    def read_office_file_with_markitdown(self, file_path):
        """MarkItDownì„ ì‚¬ìš©í•˜ì—¬ Office ë¬¸ì„œ ì½ê¸° (Word, Excel, PowerPoint)"""
        if not MARKITDOWN_AVAILABLE:
            return None
            
        try:
            print("MarkItDownì„ ì‚¬ìš©í•˜ì—¬ Office ë¬¸ì„œ ë³€í™˜ ì¤‘...")
            result = self.markitdown.convert(file_path)
            return result.text_content
        except Exception as e:
            print(f"âš ï¸ MarkItDown Office ë¬¸ì„œ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None
    
    def read_powerpoint_file(self, file_path):
        """PowerPoint íŒŒì¼ì„ Markdown í˜•ì‹ìœ¼ë¡œ ì½ê¸° - MarkItDown ìš°ì„  ì‚¬ìš©"""
        # MarkItDown ìš°ì„  ì‹œë„
        if MARKITDOWN_AVAILABLE:
            content = self.read_office_file_with_markitdown(file_path)
            if content is not None:
                return content
        
        # MarkItDown ì‹¤íŒ¨ì‹œ ê¸°ì¡´ ë°©ë²• ì‚¬ìš©
        if not PPTX_AVAILABLE:
            raise ValueError("python-pptx ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            prs = Presentation(file_path)
            markdown_content = []
            
            for slide_num, slide in enumerate(prs.slides, 1):
                markdown_content.append(f"# ìŠ¬ë¼ì´ë“œ {slide_num}\n")
                
                for shape in slide.shapes:
                    if hasattr(shape, "text") and shape.text.strip():
                        text = shape.text.strip()
                        # ì œëª©ì¸ ê²½ìš° (ì¼ë°˜ì ìœ¼ë¡œ ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸ ë°•ìŠ¤)
                        if shape == slide.shapes[0]:
                            markdown_content.append(f"## {text}\n")
                        else:
                            markdown_content.append(f"{text}\n")
                
                markdown_content.append("")
            
            return "\n\n".join(markdown_content)
        except Exception as e:
            raise ValueError(f"PowerPoint íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
    
    def detect_file_type_and_read(self, file_path):
        """íŒŒì¼ í™•ì¥ìë¥¼ ê°ì§€í•˜ê³  ì ì ˆí•œ ë°©ë²•ìœ¼ë¡œ ì½ê¸°"""
        _, ext = os.path.splitext(file_path.lower())
        
        print(f"íŒŒì¼ í˜•ì‹ ê°ì§€: {ext}")
        
        if ext in ['.txt', '.md']:
            return self.load_document_text(file_path)
        elif ext in ['.docx', '.doc']:
            content = self.read_word_file(file_path)
            return content, 'utf-8'
        elif ext == '.pdf':
            content = self.read_pdf_file(file_path)
            return content, 'utf-8'
        elif ext in ['.xlsx', '.xls']:
            content = self.read_excel_file(file_path)
            return content, 'utf-8'
        elif ext in ['.pptx', '.ppt']:
            content = self.read_powerpoint_file(file_path)
            return content, 'utf-8'
        else:
            # ì•Œ ìˆ˜ ì—†ëŠ” í™•ì¥ìëŠ” í…ìŠ¤íŠ¸ë¡œ ì‹œë„
            print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì‹œë„í•©ë‹ˆë‹¤: {ext}")
            return self.load_document_text(file_path)
    
    def load_document_text(self, file_path, encoding_list=['euc-kr', 'utf-8', 'cp949']):
        """í…ìŠ¤íŠ¸ ë¬¸ì„œ ë¡œë“œ (ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„)"""
        print(f"í…ìŠ¤íŠ¸ ë¬¸ì„œ ë¡œë”© ì¤‘: {file_path}")
        
        for encoding in encoding_list:
            try:
                with open(file_path, "r", encoding=encoding) as f:
                    text = f.read()
                print(f"âœ… {encoding} ì¸ì½”ë”©ìœ¼ë¡œ ë¬¸ì„œ ë¡œë“œ ì„±ê³µ")
                return text, encoding
            except UnicodeDecodeError:
                continue
        
        raise ValueError(f"ì§€ì›í•˜ëŠ” ì¸ì½”ë”©ìœ¼ë¡œ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {encoding_list}")
    
    def load_document(self, file_path):
        """í†µí•© ë¬¸ì„œ ë¡œë” - íŒŒì¼ í˜•ì‹ì— ë”°ë¼ ìë™ìœ¼ë¡œ ì ì ˆí•œ ë°©ë²• ì„ íƒ"""
        return self.detect_file_type_and_read(file_path)
        return self.detect_file_type_and_read(file_path)
    
    def create_collection(self, collection_name, document_path):
        """ë¬¸ì„œë¡œë¶€í„° ChromaDB ì»¬ë ‰ì…˜ ìƒì„±"""
        print(f"\n=== '{collection_name}' ì»¬ë ‰ì…˜ ìƒì„± ===")
        
        # ì»¬ë ‰ì…˜ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        existing_collections = [col.name for col in self.client.list_collections()]
        if collection_name in existing_collections:
            print(f"âš ï¸  '{collection_name}' ì»¬ë ‰ì…˜ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
            response = input("ê¸°ì¡´ ì»¬ë ‰ì…˜ì„ ë®ì–´ì“°ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
            if response not in ['y', 'yes']:
                print("ì‘ì—…ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
                return None
            else:
                self.client.delete_collection(name=collection_name)
                print("ê¸°ì¡´ ì»¬ë ‰ì…˜ì„ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")
        
        # ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±
        collection = self.client.create_collection(name=collection_name)
        
        # ë¬¸ì„œ ë¡œë“œ
        text, encoding = self.load_document(document_path)
        print(f"ë¬¸ì„œ í¬ê¸°: {len(text)} ë¬¸ì")
        
        # í…ìŠ¤íŠ¸ ë¶„í• 
        # í° ë¬¸ì„œì˜ ê²½ìš° ì²­í¬ í¬ê¸° ìë™ ì¡°ì •
        large_doc_threshold = self.settings["search"]["large_doc_threshold"]
        if len(text) > large_doc_threshold:  # ì„¤ì •ê°’ ì´ìƒì¸ ê²½ìš°
            chunk_size = self.settings["search"]["large_doc_chunk_size"]
            overlap = self.settings["search"]["large_doc_overlap"]
            print(f"ğŸ“„ í° ë¬¸ì„œ ê°ì§€ - ì²­í¬ í¬ê¸°ë¥¼ {chunk_size}ìë¡œ ì¡°ì •í•©ë‹ˆë‹¤.")
        else:
            chunk_size = self.settings["search"]["chunk_size"]
            overlap = self.settings["search"]["overlap"]
            
        chunks, metadata = self.split_text(text, chunk_size=chunk_size, overlap=overlap)
        print(f"í…ìŠ¤íŠ¸ë¥¼ {len(chunks)}ê°œ ì²­í¬ë¡œ ë¶„í• í–ˆìŠµë‹ˆë‹¤.")
        
        # ChromaDBì— ì €ì¥í•˜ë©´ì„œ ê°œë³„ì ìœ¼ë¡œ ì„ë² ë”© ìƒì„±
        print("ì²­í¬ë³„ ì„ë² ë”© ìƒì„± ë° ì €ì¥ ì¤‘...")
        
        # ë¬¸ì„œ ID ìƒì„± (íŒŒì¼ëª… ê¸°ë°˜)
        doc_name = os.path.basename(document_path)
        doc_id_base = doc_name.replace('.', '_')
        
        # ì²­í¬ë¥¼ ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ChromaDBì— ì €ì¥
        batch_size = self.settings["embedding_model"].get("batch_size", 1000)  # ì„¤ì •ì—ì„œ ê°€ì ¸ì˜¤ê±°ë‚˜ ê¸°ë³¸ê°’ ì‚¬ìš©
        total_processed = 0
        
        print(f"ë°°ì¹˜ í¬ê¸°: {batch_size}ê°œì”© ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        
        for i in range(0, len(chunks), batch_size):
            batch_chunks = chunks[i:i+batch_size]
            batch_metadata = metadata[i:i+batch_size]
            current_batch_size = len(batch_chunks)
            
            print(f"   ë°°ì¹˜ {i//batch_size + 1}/{(len(chunks) + batch_size - 1)//batch_size} ì²˜ë¦¬ ì¤‘... ({current_batch_size}ê°œ ì²­í¬)")
            
            try:
                # ë°°ì¹˜ë³„ ì„ë² ë”© ìƒì„±
                batch_embeddings = self.model.encode(batch_chunks, show_progress_bar=False)
                
                # ë°°ì¹˜ë³„ ID ë° ë©”íƒ€ë°ì´í„° ìƒì„±
                batch_ids = [f"{doc_id_base}_chunk_{i+j}" for j in range(current_batch_size)]
                
                # ë©”íƒ€ë°ì´í„°ì— ë¬¸ì„œ ì •ë³´ ì¶”ê°€
                enhanced_batch_metadata = []
                for j, meta in enumerate(batch_metadata):
                    meta.update({
                        "document_name": doc_name,
                        "document_path": document_path,
                        "encoding": encoding,
                        "chunk_text_preview": batch_chunks[j][:100] + "..." if len(batch_chunks[j]) > 100 else batch_chunks[j]
                    })
                    enhanced_batch_metadata.append(meta)
                
                # ChromaDBì— ë°°ì¹˜ ì¶”ê°€
                collection.add(
                    embeddings=[emb.tolist() if hasattr(emb, 'tolist') else emb for emb in batch_embeddings],
                    documents=batch_chunks,
                    metadatas=enhanced_batch_metadata,
                    ids=batch_ids
                )
                
                total_processed += current_batch_size
                print(f"     âœ… {current_batch_size}ê°œ ì²­í¬ ì €ì¥ ì™„ë£Œ (ì´ {total_processed}/{len(chunks)})")
                
            except Exception as e:
                print(f"     âŒ ë°°ì¹˜ {i//batch_size + 1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                
                # ê°œë³„ ì²­í¬ë¡œ ë‹¤ì‹œ ì‹œë„
                print(f"     ğŸ”„ ê°œë³„ ì²­í¬ ì²˜ë¦¬ë¡œ ì¬ì‹œë„...")
                for j, chunk in enumerate(batch_chunks):
                    try:
                        # ê°œë³„ ì„ë² ë”© ìƒì„±
                        embedding = self.model.encode([chunk], show_progress_bar=False)[0]
                        
                        # ê°œë³„ ID ë° ë©”íƒ€ë°ì´í„°
                        chunk_id = f"{doc_id_base}_chunk_{i+j}"
                        chunk_meta = batch_metadata[j].copy()
                        chunk_meta.update({
                            "document_name": doc_name,
                            "document_path": document_path,
                            "encoding": encoding,
                            "chunk_text_preview": chunk[:100] + "..." if len(chunk) > 100 else chunk
                        })
                        
                        # ChromaDBì— ê°œë³„ ì¶”ê°€
                        collection.add(
                            embeddings=[embedding.tolist() if hasattr(embedding, 'tolist') else embedding],
                            documents=[chunk],
                            metadatas=[chunk_meta],
                            ids=[chunk_id]
                        )
                        
                        total_processed += 1
                        
                    except Exception as inner_e:
                        print(f"       âš ï¸ ì²­í¬ {i+j+1} ìŠ¤í‚µ (ì˜¤ë¥˜: {inner_e})")
                        continue
        
        print(f"âœ… ì´ {total_processed}ê°œ ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ")
        
        # ChromaDBì— ì €ì¥ ì™„ë£Œ ë©”ì‹œì§€ (ê¸°ì¡´ ì €ì¥ ë¡œì§ ì œê±°)
        
        print(f"âœ… '{collection_name}' ì»¬ë ‰ì…˜ ìƒì„± ì™„ë£Œ!")
        print(f"   - ë¬¸ì„œ: {doc_name}")
        print(f"   - ì²˜ë¦¬ëœ ì²­í¬ ìˆ˜: {total_processed}")
        print(f"   - ì¸ì½”ë”©: {encoding}")
        
        return collection
    
    def list_collections(self):
        """ì €ì¥ëœ ì»¬ë ‰ì…˜ ëª©ë¡ ì¶œë ¥"""
        collections = self.client.list_collections()
        print(f"\n=== ì €ì¥ëœ ì»¬ë ‰ì…˜ ëª©ë¡ ===")
        if not collections:
            print("ì €ì¥ëœ ì»¬ë ‰ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
            return collections
            
        for i, collection in enumerate(collections):
            print(f"{i+1}. {collection.name}")
            # ì»¬ë ‰ì…˜ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            count = collection.count()
            print(f"   - ë¬¸ì„œ ì²­í¬ ìˆ˜: {count}")
            
            # ì»¬ë ‰ì…˜ì˜ ì²« ë²ˆì§¸ ë¬¸ì„œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            try:
                sample = collection.peek(limit=1)
                if sample['metadatas'] and len(sample['metadatas']) > 0:
                    metadata = sample['metadatas'][0]
                    doc_name = metadata.get('document_name', 'Unknown')
                    doc_path = metadata.get('document_path', 'Unknown')
                    encoding = metadata.get('encoding', 'Unknown')
                    print(f"   - ë¬¸ì„œëª…: {doc_name}")
                    print(f"   - íŒŒì¼ê²½ë¡œ: {doc_path}")
                    print(f"   - ì¸ì½”ë”©: {encoding}")
            except:
                print("   - ë©”íƒ€ë°ì´í„° ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print()
        
        return collections
    
    def generate_collection_name(self, document_path):
        """ë¬¸ì„œ ê²½ë¡œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³ ìœ í•œ ì»¬ë ‰ì…˜ëª… ìƒì„±"""
        doc_name = os.path.basename(document_path)
        name_without_ext = os.path.splitext(doc_name)[0]
        # íŠ¹ìˆ˜ë¬¸ìë¥¼ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½
        safe_name = "".join(c if c.isalnum() or c in '-_' else '_' for c in name_without_ext)
        return safe_name
    
    def add_document(self, document_path, collection_name=None):
        """ë¬¸ì„œë¥¼ ê³ ìœ í•œ ì»¬ë ‰ì…˜ìœ¼ë¡œ ì¶”ê°€"""
        # docs í´ë”ì—ì„œ íŒŒì¼ ì°¾ê¸° ì‹œë„
        full_path = get_docs_path(document_path)
        
        if not os.path.exists(full_path):
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {document_path}")
            # docs í´ë” ë‚´ íŒŒì¼ ëª©ë¡ ì œì•ˆ
            docs_folder = self.settings["paths"]["docs_folder"]
            if os.path.exists(docs_folder):
                files = [f for f in os.listdir(docs_folder) if os.path.isfile(os.path.join(docs_folder, f))]
                if files:
                    print(f"ğŸ’¡ '{docs_folder}' í´ë”ì˜ ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒì¼:")
                    for file in files[:10]:  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ
                        print(f"   - {file}")
                    if len(files) > 10:
                        print(f"   ... ì™¸ {len(files) - 10}ê°œ íŒŒì¼")
            return None
        
        # ì»¬ë ‰ì…˜ëª…ì´ ì œê³µë˜ì§€ ì•Šìœ¼ë©´ ìë™ ìƒì„±
        if collection_name is None:
            collection_name = self.generate_collection_name(full_path)
            print(f"ğŸ“ ìë™ ìƒì„±ëœ ì»¬ë ‰ì…˜ëª…: {collection_name}")
        
        return self.create_collection(collection_name, full_path)
    
    def get_collection_details(self, collection_name):
        """íŠ¹ì • ì»¬ë ‰ì…˜ì˜ ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
        try:
            collection = self.client.get_collection(name=collection_name)
            count = collection.count()
            
            print(f"\n=== '{collection_name}' ì»¬ë ‰ì…˜ ìƒì„¸ ì •ë³´ ===")
            print(f"ì´ ì²­í¬ ìˆ˜: {count}")
            
            if count > 0:
                # ìƒ˜í”Œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                sample = collection.peek(limit=5)
                
                if sample['metadatas'] and len(sample['metadatas']) > 0:
                    metadata = sample['metadatas'][0]
                    print(f"ë¬¸ì„œëª…: {metadata.get('document_name', 'Unknown')}")
                    print(f"íŒŒì¼ê²½ë¡œ: {metadata.get('document_path', 'Unknown')}")
                    print(f"ì¸ì½”ë”©: {metadata.get('encoding', 'Unknown')}")
                
                print(f"\nì²« {min(5, count)}ê°œ ì²­í¬ ë¯¸ë¦¬ë³´ê¸°:")
                for i, (doc, meta) in enumerate(zip(sample['documents'], sample['metadatas'])):
                    if doc and meta:
                        preview = doc[:100] + "..." if len(doc) > 100 else doc
                        print(f"{i+1}. [{meta.get('chunk_id', i)}] {preview}")
            
            return collection
            
        except Exception as e:
            print(f"âŒ ì»¬ë ‰ì…˜ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            return None
    
    def delete_collection(self, collection_name):
        """ì»¬ë ‰ì…˜ ì‚­ì œ - ChromaDB ë‚´ë¶€ íŒŒì¼ë„ í•¨ê»˜ ì •ë¦¬"""
        try:
            # ì»¬ë ‰ì…˜ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            existing_collections = [col.name for col in self.client.list_collections()]
            if collection_name not in existing_collections:
                print(f"âŒ '{collection_name}' ì»¬ë ‰ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # ì»¬ë ‰ì…˜ ì •ë³´ ë¨¼ì € ê°€ì ¸ì˜¤ê¸°
            collection = self.client.get_collection(name=collection_name)
            count = collection.count()
            
            # ì‚­ì œ í™•ì¸
            print(f"âš ï¸  '{collection_name}' ì»¬ë ‰ì…˜ì„ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
            print(f"   - ì´ ì²­í¬ ìˆ˜: {count}ê°œ")
            response = input("ì´ ì‘ì—…ì€ ë˜ëŒë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (y/N): ").strip().lower()
            if response not in ['y', 'yes']:
                print("ì‚­ì œë¥¼ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
                return False
            
            # ì»¬ë ‰ì…˜ ì‚­ì œ
            print("ğŸ—‘ï¸ ì»¬ë ‰ì…˜ ë° ê´€ë ¨ íŒŒì¼ ì‚­ì œ ì¤‘...")
            self.client.delete_collection(name=collection_name)
            
            # ChromaDB ë””ë ‰í† ë¦¬ì—ì„œ ê´€ë ¨ íŒŒì¼ ì •ë¦¬ (ì„ íƒì )
            import shutil
            import glob
            chroma_path = os.path.abspath(self.db_path)
            
            # ì»¬ë ‰ì…˜ UUID ê¸°ë°˜ ë””ë ‰í† ë¦¬ë“¤ í™•ì¸
            collection_dirs = glob.glob(os.path.join(chroma_path, "*-*-*-*-*"))
            
            # ë¹ˆ ë””ë ‰í† ë¦¬ë‚˜ ì„ì‹œ íŒŒì¼ ì •ë¦¬
            cleaned_count = 0
            for dir_path in collection_dirs:
                try:
                    # ë””ë ‰í† ë¦¬ê°€ ë¹„ì–´ìˆê±°ë‚˜ ë¶ˆì™„ì „í•œ ê²½ìš° ì •ë¦¬
                    if os.path.isdir(dir_path):
                        files = os.listdir(dir_path)
                        # í•„ìˆ˜ íŒŒì¼ë“¤ì´ ì—†ê±°ë‚˜ ë¹„ì–´ìˆëŠ” ê²½ìš°
                        required_files = ['data_level0.bin', 'header.bin', 'length.bin', 'link_lists.bin']
                        if not any(f in files for f in required_files) or len(files) == 0:
                            shutil.rmtree(dir_path)
                            cleaned_count += 1
                except Exception as e:
                    # ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ê³„ì† ì§„í–‰
                    pass
            
            if cleaned_count > 0:
                print(f"ğŸ§¹ ì •ë¦¬ëœ ë¹ˆ ë””ë ‰í† ë¦¬: {cleaned_count}ê°œ")
            
            print(f"âœ… '{collection_name}' ì»¬ë ‰ì…˜ì´ ì™„ì „íˆ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return True
            
        except Exception as e:
            print(f"âŒ ì»¬ë ‰ì…˜ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return False
    
    def cleanup_database(self):
        """ChromaDB ë°ì´í„°ë² ì´ìŠ¤ ì „ì²´ ì •ë¦¬"""
        try:
            print("ğŸ§¹ ChromaDB ë°ì´í„°ë² ì´ìŠ¤ ì •ë¦¬ ì¤‘...")
            
            # í˜„ì¬ ì»¬ë ‰ì…˜ ëª©ë¡ í™•ì¸
            collections = self.client.list_collections()
            active_collections = [col.name for col in collections]
            
            print(f"í™œì„± ì»¬ë ‰ì…˜: {len(active_collections)}ê°œ")
            
            # ChromaDB ë””ë ‰í† ë¦¬ ì •ë¦¬
            import shutil
            import glob
            chroma_path = os.path.abspath(self.db_path)
            
            if not os.path.exists(chroma_path):
                print("ChromaDB ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                return True
            
            # ì»¬ë ‰ì…˜ UUID ê¸°ë°˜ ë””ë ‰í† ë¦¬ë“¤ í™•ì¸
            collection_dirs = glob.glob(os.path.join(chroma_path, "*-*-*-*-*"))
            cleaned_count = 0
            
            for dir_path in collection_dirs:
                try:
                    if os.path.isdir(dir_path):
                        files = os.listdir(dir_path)
                        # í•„ìˆ˜ íŒŒì¼ë“¤ì´ ì—†ê±°ë‚˜ ë¹„ì–´ìˆëŠ” ë””ë ‰í† ë¦¬ ì •ë¦¬
                        required_files = ['data_level0.bin', 'header.bin', 'length.bin', 'link_lists.bin']
                        if not any(f in files for f in required_files) or len(files) == 0:
                            shutil.rmtree(dir_path)
                            cleaned_count += 1
                            print(f"   ğŸ—‘ï¸ ì •ë¦¬ë¨: {os.path.basename(dir_path)}")
                except Exception as e:
                    print(f"   âš ï¸ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {os.path.basename(dir_path)} - {e}")
                    continue
            
            print(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ ì •ë¦¬ ì™„ë£Œ - ì •ë¦¬ëœ ë””ë ‰í† ë¦¬: {cleaned_count}ê°œ")
            return True
            
        except Exception as e:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def show_help(self):
        """ë„ì›€ë§ í‘œì‹œ"""
        print("\n" + "="*60)
        print("ğŸ“š TinyRAG - ê°€ë²¼ìš´ ì˜¤í”„ë¼ì¸ ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ")
        supported_extensions = self.get_supported_extensions()
        print(f"ì§€ì› í˜•ì‹: {', '.join(supported_extensions)}")
        print("\nëª…ë ¹ì–´:")
        print("  add <íŒŒì¼ê²½ë¡œ> [ì»¬ë ‰ì…˜ëª…]  : ìƒˆ ë¬¸ì„œ ì¶”ê°€ (ì»¬ë ‰ì…˜ëª… ìƒëµì‹œ ìë™ìƒì„±)")
        print("  add <íŒŒì¼ëª…>             : docs í´ë”ì˜ íŒŒì¼ ì¶”ê°€ (íŒŒì¼ëª…ë§Œìœ¼ë¡œë„ ê°€ëŠ¥)")
        print("  add \"íŒŒì¼ ì´ë¦„.docx\"      : ê³µë°±ì´ ìˆëŠ” íŒŒì¼ëª…ì€ ë”°ì˜´í‘œ ì‚¬ìš©")
        print("  list                     : ì»¬ë ‰ì…˜ ëª©ë¡ ë³´ê¸°")
        print("  detail <ì»¬ë ‰ì…˜ëª…>        : ì»¬ë ‰ì…˜ ìƒì„¸ ì •ë³´ ë³´ê¸°")
        print("  delete <ì»¬ë ‰ì…˜ëª…>        : ì»¬ë ‰ì…˜ ì‚­ì œ (ê´€ë ¨ íŒŒì¼ë„ ì •ë¦¬)")
        print("  cleanup                  : ë°ì´í„°ë² ì´ìŠ¤ ì „ì²´ ì •ë¦¬")
        print("  extensions               : ì§€ì›ë˜ëŠ” íŒŒì¼ í˜•ì‹ ìƒì„¸ ë³´ê¸°")
        print("  help                     : ì´ ë„ì›€ë§ í‘œì‹œ")
        print("  quit                     : ì¢…ë£Œ")
        print("="*60)

def main():
    # ë¬¸ì„œ ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
    processor = DocumentProcessor()
    
    # ì§€ì›ë˜ëŠ” íŒŒì¼ í˜•ì‹ í‘œì‹œ
    supported_extensions = processor.get_supported_extensions()
    
    # ëŒ€í™”í˜• ëª¨ë“œ (ê¸°ë³¸ ë¬¸ì„œ ì²˜ë¦¬ ì œê±°)
    processor.show_help()
    
    while True:
        try:
            command = input("\nğŸ’¾ ëª…ë ¹: ").strip()
            
            if command.lower() in ['quit', 'exit', 'ì¢…ë£Œ', 'q']:
                print("ğŸ‘‹ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            elif command.lower() == 'list':
                processor.list_collections()
            
            elif command.lower() in ['help', 'h', 'ë„ì›€ë§']:
                processor.show_help()
            
            elif command.startswith('delete '):
                collection_name = command[7:].strip()
                if collection_name:
                    processor.delete_collection(collection_name)
                else:
                    print("ì‚¬ìš©ë²•: delete <ì»¬ë ‰ì…˜ëª…>")
            
            elif command.lower() == 'cleanup':
                print("âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì „ì²´ë¥¼ ì •ë¦¬í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
                response = input("ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” íŒŒì¼ë“¤ì´ ì‚­ì œë©ë‹ˆë‹¤. (y/N): ").strip().lower()
                if response in ['y', 'yes']:
                    processor.cleanup_database()
                else:
                    print("ì •ë¦¬ë¥¼ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
            
            elif command.lower() == 'extensions':
                print("\n=== ì§€ì›ë˜ëŠ” íŒŒì¼ í˜•ì‹ ===")
                extensions = processor.get_supported_extensions()
                
                print("ğŸ“„ í…ìŠ¤íŠ¸ íŒŒì¼:")
                print("  - .txt, .md (í•­ìƒ ì§€ì›)")
                
                if MARKITDOWN_AVAILABLE:
                    print("ğŸš€ MarkItDown (Microsoft) - ëª¨ë“  Office ë¬¸ì„œ ê³ í’ˆì§ˆ ë³€í™˜:")
                    print("  - .pdf, .docx, .doc, .xlsx, .xls, .pptx, .ppt")
                    print("  - Markdown í˜•ì‹ìœ¼ë¡œ ìµœì í™”ëœ ë³€í™˜ ì œê³µ")
                else:
                    print("ğŸš€ MarkItDown: âŒ (pip install markitdown)")
                
                if DOCX_AVAILABLE:
                    print("ğŸ“ Microsoft Word (ê¸°ë³¸ ì§€ì›):")
                    print("  - .docx, .doc (Markdown í˜•ì‹ìœ¼ë¡œ ë³€í™˜)")
                else:
                    print("ğŸ“ Microsoft Word: âŒ (python-docx ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”)")
                
                if PDF_AVAILABLE or PYMUPDF_AVAILABLE:
                    print("ğŸ“‘ PDF íŒŒì¼ (ê¸°ë³¸ ì§€ì›):")
                    if PYMUPDF_AVAILABLE:
                        print("  - .pdf (PyMuPDF ì‚¬ìš© - ê³ í’ˆì§ˆ)")
                    else:
                        print("  - .pdf (PyPDF2 ì‚¬ìš©)")
                else:
                    print("ğŸ“‘ PDF íŒŒì¼: âŒ (PyPDF2 ë˜ëŠ” PyMuPDF ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”)")
                
                if EXCEL_AVAILABLE:
                    print("ğŸ“Š Microsoft Excel (ê¸°ë³¸ ì§€ì›):")
                    print("  - .xlsx, .xls (Markdown í‘œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜)")
                else:
                    print("ğŸ“Š Microsoft Excel: âŒ (openpyxl ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”)")
                
                if PPTX_AVAILABLE:
                    print("ğŸ“º Microsoft PowerPoint (ê¸°ë³¸ ì§€ì›):")
                    print("  - .pptx, .ppt (Markdown í˜•ì‹ìœ¼ë¡œ ë³€í™˜)")
                else:
                    print("ğŸ“º Microsoft PowerPoint: âŒ (python-pptx ë¼ì´ë¸ŒëŸ¬ë¦¬ í•„ìš”)")
                
                print(f"\nì´ ì§€ì› í™•ì¥ì: {', '.join(extensions)}")
                print("\nâ­ ê¶Œì¥ ì„¤ì¹˜ (ìµœê³  í’ˆì§ˆ):")
                if not MARKITDOWN_AVAILABLE:
                    print("  pip install markitdown")
                print("\nì„ íƒì  ì„¤ì¹˜ (ê¸°ë³¸ ì§€ì›ìš©):")
                missing = []
                if not DOCX_AVAILABLE: missing.append("python-docx")
                if not (PDF_AVAILABLE or PYMUPDF_AVAILABLE): missing.append("PyPDF2 ë˜ëŠ” PyMuPDF")
                if not EXCEL_AVAILABLE: missing.append("openpyxl")
                if not PPTX_AVAILABLE: missing.append("python-pptx")
                
                if missing:
                    print(f"  pip install {' '.join(missing)}")
                else:
                    print("  ëª¨ë“  ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤! ğŸ‰")
            
            elif command.startswith('detail '):
                collection_name = command[7:].strip()
                if collection_name:
                    processor.get_collection_details(collection_name)
                else:
                    print("ì‚¬ìš©ë²•: detail <ì»¬ë ‰ì…˜ëª…>")
            
            elif command.startswith('add '):
                # íŒŒì¼ëª…ì— ê³µë°±ì´ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë” ì •í™•í•œ íŒŒì‹±
                command_part = command[4:].strip()  # 'add ' ì œê±°
                
                # í°ë”°ì˜´í‘œë¡œ ë‘˜ëŸ¬ì‹¸ì¸ íŒŒì¼ ê²½ë¡œ ì²˜ë¦¬
                if command_part.startswith('"'):
                    # "íŒŒì¼ê²½ë¡œ" ì»¬ë ‰ì…˜ëª… í˜•íƒœ
                    end_quote = command_part.find('"', 1)
                    if end_quote != -1:
                        file_path = command_part[1:end_quote]
                        remaining = command_part[end_quote+1:].strip()
                        collection_name = remaining if remaining else None
                    else:
                        print("âŒ íŒŒì¼ ê²½ë¡œì˜ ë”°ì˜´í‘œê°€ ì œëŒ€ë¡œ ë‹«íˆì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                        continue
                else:
                    # ê³µë°±ì„ ê¸°ì¤€ìœ¼ë¡œ ë¶„í• í•˜ë˜, ë§ˆì§€ë§‰ ë¶€ë¶„ì„ ì»¬ë ‰ì…˜ëª…ìœ¼ë¡œ ì²˜ë¦¬
                    parts = command_part.split()
                    if len(parts) == 0:
                        print("ì‚¬ìš©ë²•: add <íŒŒì¼ê²½ë¡œ> [ì»¬ë ‰ì…˜ëª…]")
                        continue
                    elif len(parts) == 1:
                        file_path = parts[0]
                        collection_name = None
                    else:
                        # ë§ˆì§€ë§‰ ë¶€ë¶„ì´ íŒŒì¼ì´ ì•„ë‹ˆë©´ ì»¬ë ‰ì…˜ëª…ìœ¼ë¡œ ê°„ì£¼
                        potential_file = ' '.join(parts[:-1])
                        potential_collection = parts[-1]
                        
                        # docs í´ë”ì—ì„œ íŒŒì¼ ì°¾ê¸° ì‹œë„
                        potential_file_full = get_docs_path(potential_file)
                        full_path_all = get_docs_path(' '.join(parts))
                        
                        if os.path.exists(potential_file_full):
                            file_path = potential_file
                            collection_name = potential_collection
                        elif os.path.exists(full_path_all):
                            file_path = ' '.join(parts)
                            collection_name = None
                        else:
                            file_path = potential_file
                            collection_name = potential_collection
                
                # ë¬¸ì„œ ì¶”ê°€ ì‹œë„
                processor.add_document(file_path, collection_name)
            
            elif command == '':
                continue
            
            else:
                print("ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì…ë‹ˆë‹¤. 'help'ë¥¼ ì…ë ¥í•˜ì—¬ ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì„ í™•ì¸í•˜ì„¸ìš”.")
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

if __name__ == "__main__":
    main()
