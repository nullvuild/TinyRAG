import chromadb
from sentence_transformers import SentenceTransformer
import requests
import json
import os
import warnings
from config import load_settings

# FutureWarning ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°
warnings.filterwarnings("ignore", category=FutureWarning)

print("=== TinyRAG - ê°€ë²¼ìš´ ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ ===")

class TinyRAG:
    def __init__(self, settings_file="settings.json"):
        # ì„¤ì • ë¡œë“œ
        self.settings = load_settings(settings_file)
        
        # ChromaDB ì„¤ì •
        chroma_db_path = self.settings["paths"]["chroma_db"]
        self.client = chromadb.PersistentClient(path=chroma_db_path)
        print("âœ… ChromaDB í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì„±ê³µ")
        
        # SentenceTransformer ëª¨ë¸ ë¡œë”©
        model_path = os.path.abspath(self.settings["embedding_model"]["local_path"])
        self.embedding_model = SentenceTransformer(model_path)
        print("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        
        # Ollama ì„¤ì •
        self.ollama_url = self.settings["ollama"]["url"]
        self.model_name = self.settings["ollama"]["model_name"]
        
        # Ollama ì—°ê²° í…ŒìŠ¤íŠ¸
        if self._test_ollama_connection():
            print(f"âœ… Ollama ì—°ê²° ì„±ê³µ (ëª¨ë¸: {self.model_name})")
        else:
            print(f"âŒ Ollama ì—°ê²° ì‹¤íŒ¨. {self.ollama_url}ì—ì„œ {self.model_name} ëª¨ë¸ì´ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
            self._suggest_available_models()
    
    def _test_ollama_connection(self):
        """Ollama ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            response = requests.get(f"{self.ollama_url}/api/tags", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def _suggest_available_models(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸ ë° ì œì•ˆ"""
        try:
            response = requests.get(f"{self.ollama_url}/api/tags", timeout=5)
            if response.status_code == 200:
                models = response.json().get('models', [])
                if models:
                    print(f"ğŸ’¡ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {[m['name'] for m in models]}")
                    # ì²« ë²ˆì§¸ ëª¨ë¸ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
                    self.model_name = models[0]['name']
                    print(f"ìë™ìœ¼ë¡œ '{self.model_name}' ëª¨ë¸ì„ ì„ íƒí–ˆìŠµë‹ˆë‹¤.")
        except:
            pass
    
    def list_collections(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ë ‰ì…˜ ëª©ë¡ ì¶œë ¥"""
        collections = self.client.list_collections()
        print(f"\nğŸ“š ì‚¬ìš© ê°€ëŠ¥í•œ ë¬¸ì„œ ì»¬ë ‰ì…˜:")
        for i, collection in enumerate(collections):
            count = collection.count()
            print(f"  {i+1}. {collection.name} ({count}ê°œ ì²­í¬)")
        return collections
    
    def search_documents(self, query, collection_name=None, n_results=None):
        """ë¬¸ì„œ ê²€ìƒ‰ - ëª¨ë“  ì»¬ë ‰ì…˜ì—ì„œ ê²€ìƒ‰í•˜ê±°ë‚˜ íŠ¹ì • ì»¬ë ‰ì…˜ì—ì„œ ê²€ìƒ‰"""
        if n_results is None:
            n_results = self.settings["search"]["default_n_results"]
        
        # ìœ ì‚¬ë„ ì„ê³„ê°’ ì„¤ì • (0.01ë¡œ ë” ë‚®ì¶¤ - ë” ë§ì€ ê²°ê³¼ í¬í•¨)
        similarity_threshold = 0.01
            
        try:
            # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            query_embedding = self.embedding_model.encode([query])
            
            all_results = {
                'documents': [[]],
                'metadatas': [[]],
                'distances': [[]]
            }
            
            # íŠ¹ì • ì»¬ë ‰ì…˜ì´ ì§€ì •ëœ ê²½ìš°
            if collection_name:
                collection = self.client.get_collection(name=collection_name)
                results = collection.query(
                    query_embeddings=query_embedding.tolist(),
                    n_results=n_results,
                    include=['documents', 'metadatas', 'distances']
                )
                return results
            
            # ëª¨ë“  ì»¬ë ‰ì…˜ì—ì„œ ê²€ìƒ‰
            collections = self.client.list_collections()
            collection_results = []
            
            print(f"ğŸ” {len(collections)}ê°œ ì»¬ë ‰ì…˜ì—ì„œ ê²€ìƒ‰ ì¤‘...")
            
            for collection in collections:
                try:
                    results = collection.query(
                        query_embeddings=query_embedding.tolist(),
                        n_results=n_results,
                        include=['documents', 'metadatas', 'distances']
                    )
                    
                    # ê²°ê³¼ê°€ ìœ íš¨í•œì§€ í™•ì¸
                    if not results or not results.get('documents') or not results['documents'][0]:
                        continue  # ì¡°ìš©íˆ ë„˜ì–´ê°
                    
                    print(f"ğŸ” ì»¬ë ‰ì…˜ '{collection.name}'ì—ì„œ {len(results['documents'][0])}ê°œ ê²°ê³¼ ë°œê²¬")
                    
                    # ì»¬ë ‰ì…˜ ì´ë¦„ì„ ë©”íƒ€ë°ì´í„°ì— ì¶”ê°€
                    for i, metadata in enumerate(results['metadatas'][0]):
                        if metadata is not None:  # metadataê°€ Noneì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì²˜ë¦¬
                            metadata['collection_name'] = collection.name
                        else:
                            # metadataê°€ Noneì¸ ê²½ìš° ìƒˆë¡œ ìƒì„±
                            results['metadatas'][0][i] = {'collection_name': collection.name}
                    
                    # ê²°ê³¼ë¥¼ ê±°ë¦¬ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê¸° ìœ„í•´ ì €ì¥
                    for doc, metadata, distance in zip(
                        results['documents'][0],
                        results['metadatas'][0], 
                        results['distances'][0]
                    ):
                        # ìœ ì‚¬ë„ ê³„ì‚° ë° ì„ê³„ê°’ í•„í„°ë§
                        similarity = 1 - distance
                        if similarity < similarity_threshold:
                            continue  # ê´€ë ¨ì„±ì´ ë„ˆë¬´ ë‚®ì€ ê²°ê³¼ëŠ” ì œì™¸
                            
                        # metadataê°€ Noneì¸ ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
                        if metadata is None:
                            metadata = {'collection_name': collection.name}
                        else:
                            metadata['collection_name'] = collection.name
                        
                        collection_results.append({
                            'document': doc,
                            'metadata': metadata,
                            'distance': distance,
                            'similarity': similarity
                        })
                        
                except Exception as e:
                    print(f"ì»¬ë ‰ì…˜ '{collection.name}' ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
                    continue
            
            # ì»¬ë ‰ì…˜ë³„ ê²°ê³¼ ë¶„ì„ ë° ì§€ëŠ¥ì  ì„ íƒ
            if collection_results:
                # ì»¬ë ‰ì…˜ë³„ë¡œ ê·¸ë£¹í™”
                collection_groups = {}
                for result in collection_results:
                    collection_name = result['metadata'].get('collection_name', 'ì•Œ ìˆ˜ ì—†ìŒ')
                    if collection_name not in collection_groups:
                        collection_groups[collection_name] = []
                    collection_groups[collection_name].append(result)
                
                # ì»¬ë ‰ì…˜ë³„ ì ìˆ˜ ê³„ì‚° (í™”ë©´ ì¶œë ¥ ì—†ì´)
                collection_scores = {}
                for collection_name, results in collection_groups.items():
                    # ìµœê³  ìœ ì‚¬ë„ì™€ í‰ê·  ìœ ì‚¬ë„ ê³„ì‚°
                    similarities = [r['similarity'] for r in results]
                    max_similarity = max(similarities)
                    avg_similarity = sum(similarities) / len(similarities)
                    
                    # ê³ í’ˆì§ˆ ê²°ê³¼ ë¹„ìœ¨ ê³„ì‚° (ìœ ì‚¬ë„ 0.1 ì´ìƒìœ¼ë¡œ ë” ë‚®ì¶¤)
                    high_quality_count = sum(1 for s in similarities if s >= 0.1)
                    quality_ratio = high_quality_count / len(similarities)
                    
                    # ì»¬ë ‰ì…˜ ì ìˆ˜ = (ìµœê³  ìœ ì‚¬ë„ * 0.5) + (í‰ê·  ìœ ì‚¬ë„ * 0.5) (í’ˆì§ˆ ë¹„ìœ¨ ì œê±°)
                    collection_score = (max_similarity * 0.5) + (avg_similarity * 0.5)
                    collection_scores[collection_name] = {
                        'score': collection_score,
                        'max_sim': max_similarity,
                        'avg_sim': avg_similarity,
                        'quality_ratio': quality_ratio,
                        'count': len(results)
                    }
                
                # ê°€ì¥ ì í•©í•œ ì»¬ë ‰ì…˜ë“¤ì—ì„œ ê²°ê³¼ ì„ íƒ
                sorted_collections = sorted(collection_scores.items(), key=lambda x: x[1]['score'], reverse=True)
                
                # ìƒìœ„ ì»¬ë ‰ì…˜ë“¤ì—ì„œ ê· í˜•ìˆê²Œ ê²°ê³¼ ì„ íƒ
                selected_results = []
                for collection_name, score_info in sorted_collections:
                    collection_results_sorted = sorted(collection_groups[collection_name], key=lambda x: x['distance'])
                    
                    # ê° ì»¬ë ‰ì…˜ì—ì„œ ì„ íƒí•  ê°œìˆ˜ ê²°ì •
                    remaining_slots = n_results - len(selected_results)
                    if remaining_slots <= 0:
                        break
                    
                    # ìƒìœ„ ì»¬ë ‰ì…˜ì€ ë” ë§ì´, í•˜ìœ„ ì»¬ë ‰ì…˜ì€ ì ê²Œ ì„ íƒ
                    if score_info['score'] >= 0.2:  # ê³ í’ˆì§ˆ ì»¬ë ‰ì…˜ (ì„ê³„ê°’ ë” ë‚®ì¶¤)
                        take_count = min(3, remaining_slots, len(collection_results_sorted))
                    elif score_info['score'] >= 0.1:  # ì¤‘í’ˆì§ˆ ì»¬ë ‰ì…˜ (ì„ê³„ê°’ ë” ë‚®ì¶¤)
                        take_count = min(2, remaining_slots, len(collection_results_sorted))
                    else:  # ì €í’ˆì§ˆ ì»¬ë ‰ì…˜
                        take_count = min(1, remaining_slots, len(collection_results_sorted))
                    
                    # ìœ ì‚¬ë„ê°€ 0.05 ì´ìƒì¸ ê²°ê³¼ë§Œ ì„ íƒ (ì„ê³„ê°’ ë” ë‚®ì¶¤)
                    quality_results = [r for r in collection_results_sorted if r['similarity'] >= 0.05]
                    if quality_results:
                        selected_results.extend(quality_results[:take_count])
                    else:  # í’ˆì§ˆ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ìµœì†Œí•œ 1ê°œëŠ” ì„ íƒ
                        selected_results.extend(collection_results_sorted[:min(1, len(collection_results_sorted))])
                
                # ìµœì¢… ê²°ê³¼ë¥¼ ìœ ì‚¬ë„ìˆœìœ¼ë¡œ ì •ë ¬
                top_results = sorted(selected_results, key=lambda x: x['distance'])[:n_results]
                
                # ê²°ê³¼ë¥¼ ChromaDB í˜•ì‹ìœ¼ë¡œ ì¬êµ¬ì„±
                for result in top_results:
                    all_results['documents'][0].append(result['document'])
                    all_results['metadatas'][0].append(result['metadata'])
                    all_results['distances'][0].append(result['distance'])
            else:
                print("âš ï¸ ëª¨ë“  ì»¬ë ‰ì…˜ì—ì„œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                print(f"   ê²€ìƒ‰ì–´: '{query}'")
                print(f"   ê²€ìƒ‰í•œ ì»¬ë ‰ì…˜ ìˆ˜: {len(collections)}")
                print("   ì„ê³„ê°’ì„ ë‚®ì¶”ê±°ë‚˜ ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
            
            return all_results
            
        except Exception as e:
            print(f"ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    def format_search_results(self, results):
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì •ë¦¬í•˜ì—¬ í‘œì‹œ"""
        if not results or not results['documents'][0]:
            return [], ""
        
        formatted_results = []
        context_parts = []
        
        # ê²€ìƒ‰ëœ ë¬¸ì„œ ëª©ë¡ê³¼ ìœ ì‚¬ë„ ì •ë³´ í‘œì‹œ
        doc_list = []
        similarity_info = []
        for i, (doc, metadata, distance) in enumerate(zip(
            results['documents'][0], 
            results['metadatas'][0], 
            results['distances'][0]
        )):
            similarity = 1 - distance
            
            # metadataê°€ Noneì¸ ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
            if metadata is None:
                metadata = {}
            
            doc_name = metadata.get('document_name', 'ì•Œ ìˆ˜ ì—†ëŠ” ë¬¸ì„œ')
            chunk_id = metadata.get('chunk_id', i)
            collection_name = metadata.get('collection_name', 'ì•Œ ìˆ˜ ì—†ìŒ')
            
            # ê²°ê³¼ ì •ë³´ ì €ì¥
            result_info = {
                'rank': i + 1,
                'document_name': doc_name,
                'chunk_id': chunk_id,
                'similarity': similarity,
                'content': doc,
                'metadata': metadata
            }
            formatted_results.append(result_info)
            
            # ë¬¸ì„œ ëª©ë¡ì— ì¶”ê°€ (ì¤‘ë³µ ì œê±°)
            doc_info = f"[{collection_name}] {doc_name}"
            if doc_info not in doc_list:
                doc_list.append(doc_info)
                # ìœ ì‚¬ë„ ì •ë³´ë„ í•¨ê»˜ ì €ì¥
                similarity_info.append(f"   â€¢ {doc_info} (ê´€ë ¨ë„: {similarity:.1%})")
            
            # ì»¨í…ìŠ¤íŠ¸ ìƒì„±ìš©
            context_parts.append(f"[ë¬¸ì„œ: {doc_name}]\n{doc}")
        
        # ê²€ìƒ‰ëœ ë¬¸ì„œ ëª©ë¡ê³¼ ìœ ì‚¬ë„ í‘œì‹œ
        print(f"\nğŸ“š ê²€ìƒ‰ëœ ë¬¸ì„œ ({len(doc_list)}ê°œ):")
        for sim_info in similarity_info:
            print(sim_info)
        
        context = "\n\n".join(context_parts)
        return formatted_results, context
    
    def generate_answer_with_sources(self, query, context, search_results):
        """ê·¼ê±°ê°€ í¬í•¨ëœ ë‹µë³€ ìƒì„±"""
        try:
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = f"""ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ì„±ì´ ë†’ì€ ë¬¸ì„œë“¤ì˜ ë‚´ìš©ì…ë‹ˆë‹¤. ì´ ë¬¸ì„œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©:
{context}

ì‚¬ìš©ì ì§ˆë¬¸: {query}

ë‹µë³€ ì§€ì¹¨:
1. ìœ„ì˜ ë¬¸ì„œ ë‚´ìš©ì—ì„œ ì§ˆë¬¸ê³¼ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ ì •ë³´ë§Œì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
2. ë¬¸ì„œì— ëª…ì‹œì ìœ¼ë¡œ ì–¸ê¸‰ë˜ì§€ ì•Šì€ ë‚´ìš©ì€ ì¶”ì¸¡í•˜ê±°ë‚˜ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.
3. ì—¬ëŸ¬ ë¬¸ì„œì˜ ë‚´ìš©ì´ ìˆë‹¤ë©´, ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
4. ë‹µë³€ì€ ëª…í™•í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ë˜, ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ í‘œí˜„í•˜ì„¸ìš”.
5. ë¬¸ì„œ ë‚´ìš©ìœ¼ë¡œëŠ” ì§ˆë¬¸ì— ì™„ì „íˆ ë‹µí•  ìˆ˜ ì—†ë‹¤ë©´, ë‹µí•  ìˆ˜ ìˆëŠ” ë¶€ë¶„ë§Œ ëª…ì‹œí•˜ê³  í•œê³„ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.

ë‹µë³€:"""

            print("ğŸ”— Ollama API í˜¸ì¶œ ì¤‘...")
            
            # Ollama API í˜¸ì¶œ
            payload = {
                "model": self.model_name,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.7,
                    "top_p": 0.9,
                    "repeat_penalty": 1.1
                }
            }
            
            print(f"ğŸ“¡ ìš”ì²­ URL: {self.ollama_url}/api/generate")
            print(f"ğŸ¯ ëª¨ë¸: {self.model_name}")
            
            response = requests.post(
                f"{self.ollama_url}/api/generate",
                json=payload,
                timeout=120,  # íƒ€ì„ì•„ì›ƒì„ 120ì´ˆë¡œ ì¦ê°€
                headers={'Content-Type': 'application/json'}
            )
            
            print(f"ğŸ“Š ì‘ë‹µ ìƒíƒœ ì½”ë“œ: {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                ai_answer = result.get("response", "").strip()
                
                if not ai_answer:
                    print("âš ï¸ ê²½ê³ : Ollamaì—ì„œ ë¹ˆ ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤.")
                    print(f"ğŸ“‹ ì „ì²´ ì‘ë‹µ: {result}")
                    ai_answer = "ì£„ì†¡í•©ë‹ˆë‹¤. AI ëª¨ë¸ì—ì„œ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                else:
                    print(f"âœ… AI ë‹µë³€ ìƒì„± ì™„ë£Œ (ê¸¸ì´: {len(ai_answer)}ì)")
                
                # ê·¼ê±° ì •ë³´ ì¶”ê°€
                sources_info = "\n\nğŸ“š ë‹µë³€ ê·¼ê±°:"
                for result in search_results:
                    collection_name = result['metadata'].get('collection_name', 'ì•Œ ìˆ˜ ì—†ìŒ')
                    
                    # ìì—°ìŠ¤ëŸ¬ìš´ ì§€ì ì—ì„œ ë‚´ìš© ìë¥´ê¸°
                    content = result['content']
                    if len(content) > 150:
                        # 150ì ê·¼ì²˜ì—ì„œ ìì—°ìŠ¤ëŸ¬ìš´ êµ¬ë¶„ì  ì°¾ê¸°
                        truncated = content[:150]
                        
                        # ë§ˆì§€ë§‰ ë¬¸ì¥ì˜ ë(.)ì„ ì°¾ê¸°
                        last_period = truncated.rfind('.')
                        if last_period > 100:  # ë„ˆë¬´ ì§§ì§€ ì•Šë‹¤ë©´ ë¬¸ì¥ ëì—ì„œ ìë¥´ê¸°
                            content_preview = content[:last_period + 1]
                        else:
                            # ë¬¸ì¥ ëì´ ì—†ìœ¼ë©´ ë§ˆì§€ë§‰ ê³µë°±ì—ì„œ ìë¥´ê¸°
                            last_space = truncated.rfind(' ')
                            if last_space > 100:  # ë„ˆë¬´ ì§§ì§€ ì•Šë‹¤ë©´ ë‹¨ì–´ ê²½ê³„ì—ì„œ ìë¥´ê¸°
                                content_preview = content[:last_space] + "..."
                            else:
                                # ì¤„ë°”ê¿ˆì—ì„œ ìë¥´ê¸°
                                last_newline = truncated.rfind('\n')
                                if last_newline > 100:
                                    content_preview = content[:last_newline] + "..."
                                else:
                                    # ë§ˆì§€ë§‰ ìˆ˜ë‹¨ìœ¼ë¡œ 150ìì—ì„œ ìë¥´ê¸°
                                    content_preview = truncated + "..."
                    else:
                        content_preview = content
                    
                    sources_info += f"\nâ€¢ [{collection_name}] {result['document_name']} - ê´€ë ¨ë„: {result['similarity']:.1%}"
                    sources_info += f"\n  ğŸ“„ ì°¸ê³  ë‚´ìš©: \"{content_preview}\"\n"
                
                return ai_answer + sources_info
            else:
                error_msg = f"Ollama API ì˜¤ë¥˜: {response.status_code}"
                try:
                    error_detail = response.json()
                    error_msg += f" - {error_detail}"
                except:
                    error_msg += f" - {response.text}"
                print(f"âŒ {error_msg}")
                return error_msg
                
        except requests.exceptions.Timeout:
            error_msg = "â° Ollama API ì‘ë‹µ ì‹œê°„ ì´ˆê³¼ (120ì´ˆ). ëª¨ë¸ì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦¬ê±°ë‚˜ ì„œë²„ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            print(f"âŒ {error_msg}")
            return error_msg
        except requests.exceptions.ConnectionError:
            error_msg = f"ğŸ”Œ Ollama ì„œë²„({self.ollama_url})ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”."
            print(f"âŒ {error_msg}")
            return error_msg
        except Exception as e:
            error_msg = f"ë‹µë³€ ìƒì„± ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}"
            print(f"âŒ {error_msg}")
            return error_msg
    
    def search_and_answer(self, query, collection_name=None, n_results=None):
        """ì™„ì „í•œ RAG ê²€ìƒ‰ ë° ë‹µë³€ - ëª¨ë“  ì»¬ë ‰ì…˜ì—ì„œ ê²€ìƒ‰í•˜ê±°ë‚˜ íŠ¹ì • ì»¬ë ‰ì…˜ì—ì„œ ê²€ìƒ‰"""
        if n_results is None:
            n_results = self.settings["search"]["default_n_results"]
            
        print(f"\nğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {query}")
        if collection_name:
            print(f"ğŸ“š ëŒ€ìƒ ì»¬ë ‰ì…˜: {collection_name}")
        else:
            print(f"ğŸ“š ê²€ìƒ‰ ë²”ìœ„: ëª¨ë“  ì»¬ë ‰ì…˜")
        print("=" * 60)
        
        # 0. Ollama ì—°ê²° ìƒíƒœ í™•ì¸
        if not self._test_ollama_connection():
            print("âš ï¸ Ollama ì„œë²„ ì—°ê²°ì„ ì¬í™•ì¸ ì¤‘...")
            self._suggest_available_models()
            if not self._test_ollama_connection():
                print("âŒ Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²€ìƒ‰ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
        
        # 1. ë¬¸ì„œ ê²€ìƒ‰
        search_results_raw = self.search_documents(query, collection_name, n_results)
        if not search_results_raw or not search_results_raw['documents'][0]:
            print("âŒ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # 2. ê²€ìƒ‰ ê²°ê³¼ ì •ë¦¬ ë° í‘œì‹œ
        search_results, context = self.format_search_results(search_results_raw)
        
        # 3. Ollamaë¡œ ë‹µë³€ ìƒì„±
        print("ğŸ¤– AI ë‹µë³€ ìƒì„± ì¤‘...")
        answer = self.generate_answer_with_sources(query, context, search_results)
        
        print("\nğŸ’¬ AI ë‹µë³€:")
        print("=" * 60)
        print(answer)
        print("=" * 60)
    
    def show_help(self):
        """ë„ì›€ë§ í‘œì‹œ"""
        print("\n" + "="*80)
        print("ğŸ” TinyRAG - ê°€ë²¼ìš´ ì˜¤í”„ë¼ì¸ ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ")
        print("ì´ì œ ëª¨ë“  ì»¬ë ‰ì…˜ì—ì„œ ìë™ìœ¼ë¡œ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë¥¼ ì°¾ìŠµë‹ˆë‹¤!")
        print(f"\nğŸ”§ í˜„ì¬ ì„¤ì •:")
        print(f"   - Ollama ì„œë²„: {self.settings['ollama']['url']}")
        print(f"   - Ollama ëª¨ë¸: {self.settings['ollama']['model_name']}")
        print(f"   - ì„ë² ë”© ëª¨ë¸: {self.settings['embedding_model']['model_name']}")
        print(f"   - ë¬¸ì„œ í´ë”: {self.settings['paths']['docs_folder']}")
        print("\nëª…ë ¹ì–´:")
        print("  <ì§ˆë¬¸>                : ëª¨ë“  ì»¬ë ‰ì…˜ì—ì„œ ê²€ìƒ‰")
        print("  use <ì»¬ë ‰ì…˜ëª…> <ì§ˆë¬¸>  : íŠ¹ì • ì»¬ë ‰ì…˜ì—ì„œë§Œ ê²€ìƒ‰")
        print("  list                  : ì»¬ë ‰ì…˜ ëª©ë¡ ë³´ê¸°")
        print("  help                  : ì´ ë„ì›€ë§ í‘œì‹œ")
        print("  quit                  : ì¢…ë£Œ")
        print("="*80)

def main():
    # Tiny RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    rag = TinyRAG()
    
    # ì»¬ë ‰ì…˜ ëª©ë¡ í™•ì¸
    collections = rag.list_collections()
    if not collections:
        print("\nâŒ ì‚¬ìš© ê°€ëŠ¥í•œ ë¬¸ì„œ ì»¬ë ‰ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("ë¨¼ì € create_db.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ë¬¸ì„œë¥¼ ChromaDBì— ì¶”ê°€í•˜ì„¸ìš”.")
        return
    
    # ê¸°ë³¸ ì»¬ë ‰ì…˜ ì„¤ì • (ë” ì´ìƒ í•„ìš”í•˜ì§€ ì•ŠìŒ)
    # default_collection = collections[0].name if collections else "main_documents"
    # current_collection = default_collection
    
    # ëŒ€í™”í˜• ê²€ìƒ‰
    print("\nğŸ’­ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (help: ë„ì›€ë§, quit: ì¢…ë£Œ)")
    
    while True:
        try:
            user_input = input(f"\nğŸ’­ ì§ˆë¬¸: ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ', 'q']:
                print("ğŸ‘‹ ê²€ìƒ‰ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            elif user_input.lower() == 'list':
                rag.list_collections()
            
            elif user_input.lower() in ['help', 'h', 'ë„ì›€ë§']:
                rag.show_help()
            
            elif user_input.startswith('use '):
                # "use <ì»¬ë ‰ì…˜ëª…> <ì§ˆë¬¸>" í˜•íƒœë¡œ íŠ¹ì • ì»¬ë ‰ì…˜ì—ì„œ ê²€ìƒ‰
                parts = user_input[4:].strip().split(' ', 1)
                if len(parts) == 2:
                    collection_name, question = parts
                    try:
                        rag.client.get_collection(name=collection_name)
                        print(f"ğŸ¯ '{collection_name}' ì»¬ë ‰ì…˜ì—ì„œë§Œ ê²€ìƒ‰í•©ë‹ˆë‹¤.")
                        rag.search_and_answer(question, collection_name)
                    except:
                        print(f"âŒ '{collection_name}' ì»¬ë ‰ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    print("âŒ ì‚¬ìš©ë²•: use <ì»¬ë ‰ì…˜ëª…> <ì§ˆë¬¸>")
            
            elif user_input == '':
                continue
            
            else:
                # ëª¨ë“  ì»¬ë ‰ì…˜ì—ì„œ RAG ê²€ìƒ‰ ë° ë‹µë³€
                rag.search_and_answer(user_input)
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ê²€ìƒ‰ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

if __name__ == "__main__":
    main()
